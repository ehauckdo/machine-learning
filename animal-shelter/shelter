#! /usr/bin/env python
from __future__ import division
import pandas
import math
import operator
import sys
import numpy
from sklearn.cross_validation import KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn import cross_validation
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import train_test_split
from sklearn.metrics import classification_report
from Tools.estimators import grid_search

outcomes = { "Adoption": 0, "Died": 1, "Euthanasia": 2,
    "Return_to_owner":3, "Transfer": 4}

svr_params = {
    "Transfer":     {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001},
    "Adoption":     {'kernel': 'linear', 'C': 1},
    "Return_to_owner":{'kernel': 'rbf', 'C': 1000, 'gamma': 0.001},
    "Died":         {'kernel': 'rbf', 'C': 1, 'gamma': 0.001},
    "Euthanasia":   {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}
}


def perform_SVR(train_set, train_target, test_set, predictors, use_subsets=True, subset_size=0.5):

    def get_outcome(animal, desired_outcome):
        outcome = animal["OutcomeType"]
        if outcome == desired_outcome:
            return 1
        else:
            return 0
    
    def get_outcome_probability(train_set, outcome, train_target, test_set):
        train_set["OutcomeType"] = train_target 
        if use_subsets is True:
            dataframe = train_set.sample(frac=subset_size)
        else:
            dataframe = train_set.copy()
            
        scaler = StandardScaler()
        dataframe[predictors] = scaler.fit_transform(dataframe[predictors])
        test_set[predictors] = scaler.transform(test_set[predictors])

        svr = SVR(**svr_params[outcome])
        svr.fit(dataframe[predictors], dataframe["OutcomeType"])
        predictions = svr.predict(test_set[predictors].astype(float))
        
        for i in range(10):
            print(predictions[i])
        
        return predictions

    outcome_column = {}
    outcome_probabilities = {}

    for key in outcomes.keys():
        outcome_column[key] = train_set.apply(get_outcome, axis=1, args=[outcomes[key]])
        outcome_probabilities[outcomes[key]] = get_outcome_probability(train_set[predictors], key, outcome_column[key], test_set[predictors])

    return outcome_probabilities 

def perform_ensemble_vote(algorithms, train_set, test_set, use_subsets=True, subset_size=0.8):

    def get_outcome(animal, desired_outcome):
        outcome = animal["OutcomeType"]
        if outcome == desired_outcome:
            return 1
        else:
            return 0

    def get_outcome_probability(train_set, outcome, train_target, test_set):
        dataframe = train_set.copy()
        dataframe["OutcomeType"] = train_target 

        total_predictions = []
        for algorithm, predictor in (algorithms):
            if use_subsets is True:
                subset = dataframe.sample(frac=subset_size)
                algorithm.fit(subset[predictor], subset["OutcomeType"])
            else:
                algorithm.fit(train_set[predictor], subset["OutcomeType"])
            prediction = algorithm.predict(test_set[predictor].astype(float))
            total_predictions.append(prediction)

        predictions = 0;
        for prediction in total_predictions:
            predictions += prediction
        
        total_votes = len(algorithms)
        predictions = numpy.divide(predictions, float(total_votes)) 
        return predictions

    outcome_column = {}
    outcome_probabilities = {}

    for key in outcomes.keys():
        outcome_column[key] = train_set.apply(get_outcome, axis=1, args=[outcomes[key]])
        outcome_probabilities[outcomes[key]] = get_outcome_probability(train_set, key, outcome_column[key], test_set)

    return outcome_probabilities 

def perform_ensemble_proba(algorithms, train_set, test_set, use_subsets=True, subset_size=0.7):

    total_predictions = []
    for algorithm, predictor in (algorithms):
        if use_subsets is True:
            subset = train_set.sample(frac=subset_size)
            algorithm.fit(subset[predictor], subset["OutcomeType"])
        else:
            algorithm.fit(train_set[predictor], subset["OutcomeType"])
        prediction = algorithm.predict_proba(test_set[predictor].astype(float))
        total_predictions.append(prediction)
  
    # average scores 
    predictions = 0;
    for prediction in total_predictions:
        predictions += prediction
    predictions = predictions/len(total_predictions)
    
    return predictions

def insert_probabilities(dataframe, predictions):

    def get_outcome_probability1(id_animal, outcome_type):
        return predictions[id_animal-1][outcomes[outcome_type]]

    def get_outcome_probability(id_animal, outcome_type):
        return predictions[outcomes[outcome_type]][id_animal-1]

    dataframe["Adoption"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Adoption"])
    dataframe["Died"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Died"])
    dataframe["Euthanasia"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Euthanasia"])
    dataframe["Return_to_owner"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Return_to_owner"])
    dataframe["Transfer"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Transfer"])

    dataframe.loc[dataframe["Adoption"] < 0, "Adoption"] = 0.0
    dataframe.loc[dataframe["Died"] < 0, "Died"] = 0.0
    dataframe.loc[dataframe["Euthanasia"] < 0, "Euthanasia"] = 0.0
    dataframe.loc[dataframe["Return_to_owner"] < 0, "Return_to_owner"] = 0.0
    dataframe.loc[dataframe["Transfer"] < 0, "Transfer"] = 0.0

    dataframe.loc[dataframe["Adoption"] > 1, "Adoption"] = 1.0
    dataframe.loc[dataframe["Died"] > 1, "Died"] = 1.0
    dataframe.loc[dataframe["Euthanasia"] > 1, "Euthanasia"] = 1.0
    dataframe.loc[dataframe["Return_to_owner"] > 1, "Return_to_owner"] = 1.0
    dataframe.loc[dataframe["Transfer"] > 1, "Transfer"] = 1.0

def generate_submission(dataframe):
    submission = pandas.DataFrame({
        "ID": dataframe["ID"],
        "Adoption": dataframe["Adoption"],
        "Died": dataframe["Died"],
        "Euthanasia": dataframe["Euthanasia"],
        "Return_to_owner": dataframe["Return_to_owner"],
        "Transfer": dataframe["Transfer"]
    })
    
    submission = submission[["ID", "Adoption", "Died", "Euthanasia", "Return_to_owner", "Transfer"]]
    submission.to_csv("kaggle.csv", index=False)

def clean_data(dataframe):

    # formatting AnimalType column
    dataframe.loc[dataframe["AnimalType"] == "Dog", "AnimalType"] = 0
    dataframe.loc[dataframe["AnimalType"] == "Cat", "AnimalType"] = 1

    # filling SexuponOutcome column
    # we are filling with the most common result
    dataframe["SexuponOutcome"] = dataframe["SexuponOutcome"].fillna("Neutered Male")

    # formatting SexuponOutcome column
    dataframe.loc[dataframe["SexuponOutcome"] == "Neutered Male", "SexuponOutcome"] = 0
    dataframe.loc[dataframe["SexuponOutcome"] == "Spayed Female", "SexuponOutcome"] = 1
    dataframe.loc[dataframe["SexuponOutcome"] == "Intact Male", "SexuponOutcome"] = 2
    dataframe.loc[dataframe["SexuponOutcome"] == "Intact Female", "SexuponOutcome"] = 3
    dataframe.loc[dataframe["SexuponOutcome"] == "Unknown", "SexuponOutcome"] = 4
   
    # formatting OutcomeType column
    # only for training set
    try: 
        dataframe.loc[dataframe["OutcomeType"] == "Adoption", "OutcomeType"] = 0 
        dataframe.loc[dataframe["OutcomeType"] == "Died", "OutcomeType"] = 1
        dataframe.loc[dataframe["OutcomeType"] == "Euthanasia", "OutcomeType"] = 2
        dataframe.loc[dataframe["OutcomeType"] == "Return_to_owner", "OutcomeType"] = 3
        dataframe.loc[dataframe["OutcomeType"] == "Transfer", "OutcomeType"] = 4 
        dataframe["OutcomeType"] = dataframe["OutcomeType"].astype(int)
    except:
        pass

    # filling AgeuponOutcome column
    # we are considering that an animal with missing age has 0 years
    dataframe["AgeuponOutcome"] = dataframe["AgeuponOutcome"].fillna(0)
   
    # formatting AgeuponOutcome column
    # terrible hack, improve this later
    def get_age(animal):
        age = str(animal["AgeuponOutcome"])
        try:
            if 'week' in age:
                return 0
            elif 'month' in age:
                value = int(age.split()[0])*(-1)
                if value < -6:
                    return -6
                return value
            else:
                return age.split()[0]
        except:
            return -1

    dataframe["AgeuponOutcome"] = dataframe.apply(get_age, axis=1)
    dataframe["AgeuponOutcome"] = dataframe["AgeuponOutcome"].astype(int)
   
    # separation between Mixed and more Pure races 
    def is_mixed(animal):
        breed = animal["Breed"]
        if "Mix" in breed or "/" in breed:
            return 1
        else:
            return 0

    dataframe["Pedigree"] = dataframe.apply(is_mixed, axis=1)

    # formatting Breed column
    # can be improved, but works
    breed_mapping = {}
    def get_breed(animal):
        breed = animal["Breed"].split(",")[0]
        try:
            breed_mapping[breed] += 1
        except KeyError:
            breed_mapping[breed] = 1
        return breed_mapping[breed]    

    def apply_breed(animal):
        breed = animal["Breed"].split(",")[0]
        return breed_mapping[breed]

    dataframe.apply(get_breed, axis=1)
    dataframe['Breed'] = dataframe.apply(apply_breed, axis=1)
    dataframe.loc[dataframe["Breed"] < 100, "Breed"] = 1

    # formatting Color column
    # can be improved, but works
    color_mapping = {} 
    def get_color(animal):
        color = animal['Color'].split(",")[0]  
        try:
            color_mapping[color] += 1
        except KeyError:
            color_mapping[color] = 1 
        return color_mapping[color]    

    def apply_color(animal):
        color = animal['Color'].split(",")[0]  
        return color_mapping[color]

    dataframe.apply(get_color, axis=1)
    dataframe['Color'] = dataframe.apply(apply_color, axis=1)
    dataframe.loc[dataframe["Color"] < 100, "Color"] = 1

    def get_identity(animal):
        name = animal['Name']
        if pandas.isnull(name):
            return 0 
        else:
            return 1
    dataframe['Identity'] = dataframe.apply(get_identity, axis=1)

    dataframe.drop('Name', axis=1, inplace=True)



shelter = pandas.read_csv("train.csv")
test = pandas.read_csv("test.csv")

clean_data(shelter)
clean_data(test)

algorithms = []
for i in range(1):
    algorithms.append([GradientBoostingClassifier(random_state=1, n_estimators=35, max_depth=5), ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"]])
for i in range(1):
    algorithms.append([RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=3), ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"]])
#for i in range(1):
#    algorithms.append([MLPClassifier(), ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"]])

#predictions = perform_ensemble_proba(algorithms, shelter, test)
#insert_probabilities(test, predictions)

#generate_submission(test)
#predictions = perform_SVM(shelter, shelter["OutcomeType"], test, ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"])
#for i in range(20):
#    print(predictions[i])


predictions = perform_SVR(shelter, shelter["OutcomeType"], test, ["AnimalType", "SexuponOutcome", "AgeuponOutcome"])
insert_probabilities(test, predictions)
generate_submission(test)
