#! /usr/bin/env python
from __future__ import division
import pandas
import math
import operator
import sys
import numpy
import random
from sklearn.cross_validation import KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn import cross_validation
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import train_test_split
from sklearn.metrics import classification_report
from Tools.estimators import grid_search

outcomes = { "Adoption": 0, "Died": 1, "Euthanasia": 2,
    "Return_to_owner":3, "Transfer": 4}

svr_params = {
    "Transfer":     {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001},
    "Adoption":     {'kernel': 'linear', 'C': 1},
    "Return_to_owner":{'kernel': 'rbf', 'C': 1000, 'gamma': 0.001},
    "Died":         {'kernel': 'rbf', 'C': 1, 'gamma': 0.001},
    "Euthanasia":   {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}
}


def perform_SVR(train_set, train_target, test_set, predictors, use_subsets=True, subset_size=0.5):

    def get_outcome(animal, desired_outcome):
        outcome = animal["OutcomeType"]
        if outcome == desired_outcome:
            return 1
        else:
            return 0
    
    def get_outcome_probability(train_set, outcome, train_target, test_set):
        train_set["OutcomeType"] = train_target 
        if use_subsets is True:
            dataframe = train_set.sample(frac=subset_size)
        else:
            dataframe = train_set.copy()
            
        scaler = StandardScaler()
        dataframe[predictors] = scaler.fit_transform(dataframe[predictors])
        test_set[predictors] = scaler.transform(test_set[predictors])

        svr = SVR(**svr_params[outcome])
        svr.fit(dataframe[predictors], dataframe["OutcomeType"])
        predictions = svr.predict(test_set[predictors].astype(float))
        
        for i in range(10):
            print(predictions[i])
        
        return predictions

    outcome_column = {}
    outcome_probabilities = {}

    for key in outcomes.keys():
        outcome_column[key] = train_set.apply(get_outcome, axis=1, args=[outcomes[key]])
        outcome_probabilities[outcomes[key]] = get_outcome_probability(train_set[predictors], key, outcome_column[key], test_set[predictors])

    return outcome_probabilities 

def perform_ensemble_vote(algorithms, train_set, test_set, use_subsets=True, subset_size=0.8):

    def get_outcome(animal, desired_outcome):
        outcome = animal["OutcomeType"]
        if outcome == desired_outcome:
            return 1
        else:
            return 0

    def get_outcome_probability(train_set, outcome, train_target, test_set):
        dataframe = train_set.copy()
        dataframe["OutcomeType"] = train_target 

        total_predictions = []
        for algorithm, predictor in (algorithms):
            if use_subsets is True:
                subset = dataframe.sample(frac=subset_size)
                algorithm.fit(subset[predictor], subset["OutcomeType"])
            else:
                algorithm.fit(train_set[predictor], subset["OutcomeType"])
            prediction = algorithm.predict(test_set[predictor].astype(float))
            total_predictions.append(prediction)

        predictions = 0;
        for prediction in total_predictions:
            predictions += prediction
        
        total_votes = len(algorithms)
        predictions = numpy.divide(predictions, float(total_votes)) 
        return predictions

    outcome_column = {}
    outcome_probabilities = {}

    for key in outcomes.keys():
        outcome_column[key] = train_set.apply(get_outcome, axis=1, args=[outcomes[key]])
        outcome_probabilities[outcomes[key]] = get_outcome_probability(train_set, key, outcome_column[key], test_set)

    return outcome_probabilities 

def perform_ensemble_proba(algorithms, train_set, test_set, use_subsets=True, subset_size=0.7):

    total_predictions = []
    for algorithm, predictor in (algorithms):
        if use_subsets is True:
            subset = train_set.sample(frac=subset_size)
            algorithm.fit(subset[predictor], subset["OutcomeType"])
        else:
            algorithm.fit(train_set[predictor], subset["OutcomeType"])
        prediction = algorithm.predict_proba(test_set[predictor].astype(float))
        total_predictions.append(prediction)
  
    # average scores 
    predictions = 0;
    for prediction in total_predictions:
        predictions += prediction
    predictions = predictions/len(total_predictions)
    
    return predictions

def perform_ensemble_proba_incremental(algorithms, train_set, test_set, subset_size=0.8):

    total_predictions = []
    intermediary_predictions = []
    total_scores = []
    for algorithm, predictor in (algorithms):
        subset_size = random.uniform(0.7, 0.9)
        random_state = algorithm.get_params()["random_state"]
        subset = train_set.sample(frac=subset_size, random_state=random_state)
        score = numpy.sqrt(-cross_validation.cross_val_score(algorithm, subset[predictor], subset["OutcomeType"], scoring='neg_log_loss', cv=3, n_jobs=3))
        if not total_scores or numpy.mean(score) < numpy.mean(total_scores):
            total_scores.append(numpy.mean(score))
            print("{0}: Mean: {1} (New score: {2}, subset_size: {3}, seed: {4})".format(len(total_predictions), numpy.mean(total_scores), numpy.mean(score), subset_size, random_state))
            algorithm.fit(subset[predictor], subset["OutcomeType"])
            prediction = algorithm.predict_proba(test_set[predictor].astype(float))
            total_predictions.append(prediction)
            if len(total_predictions) % 10 is 0:
                intermediary = numpy.mean(total_predictions, axis=0)
                intermediary_predictions.append([intermediary, len(total_predictions), numpy.mean(total_scores)])
    intermediary = numpy.mean(total_predictions, axis=0)
    intermediary_predictions.append([intermediary, len(total_predictions), numpy.mean(total_scores)])
    return intermediary_predictions 

def insert_probabilities(dataframe, predictions):

    def get_outcome_probability(id_animal, outcome_type):
        return predictions[id_animal-1][outcomes[outcome_type]]

    def get_outcome_probability1(id_animal, outcome_type):
        return predictions[outcomes[outcome_type]][id_animal-1]

    dataframe["Adoption"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Adoption"])
    dataframe["Died"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Died"])
    dataframe["Euthanasia"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Euthanasia"])
    dataframe["Return_to_owner"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Return_to_owner"])
    dataframe["Transfer"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Transfer"])

    dataframe.loc[dataframe["Adoption"] < 0, "Adoption"] = 0.0
    dataframe.loc[dataframe["Died"] < 0, "Died"] = 0.0
    dataframe.loc[dataframe["Euthanasia"] < 0, "Euthanasia"] = 0.0
    dataframe.loc[dataframe["Return_to_owner"] < 0, "Return_to_owner"] = 0.0
    dataframe.loc[dataframe["Transfer"] < 0, "Transfer"] = 0.0

    dataframe.loc[dataframe["Adoption"] > 1, "Adoption"] = 1.0
    dataframe.loc[dataframe["Died"] > 1, "Died"] = 1.0
    dataframe.loc[dataframe["Euthanasia"] > 1, "Euthanasia"] = 1.0
    dataframe.loc[dataframe["Return_to_owner"] > 1, "Return_to_owner"] = 1.0
    dataframe.loc[dataframe["Transfer"] > 1, "Transfer"] = 1.0
    
    submission = pandas.DataFrame({
        "ID": dataframe["ID"],
        "Adoption": dataframe["Adoption"],
        "Died": dataframe["Died"],
        "Euthanasia": dataframe["Euthanasia"],
        "Return_to_owner": dataframe["Return_to_owner"],
        "Transfer": dataframe["Transfer"]
    })
    
    submission = submission[["ID", "Adoption", "Died", "Euthanasia", "Return_to_owner", "Transfer"]]
    submission.to_csv("kaggle.csv", index=False)

def insert_probabilities_incremental(dataframe, all_predictions):

    for predictions, num_models, score in all_predictions: 

        def get_outcome_probability(id_animal, outcome_type):
            return predictions[id_animal-1][outcomes[outcome_type]]

        def get_outcome_probability1(id_animal, outcome_type):
            return predictions[outcomes[outcome_type]][id_animal-1]

        dataframe["Adoption"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Adoption"])
        dataframe["Died"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Died"])
        dataframe["Euthanasia"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Euthanasia"])
        dataframe["Return_to_owner"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Return_to_owner"])
        dataframe["Transfer"] = dataframe[["ID"]].apply(get_outcome_probability, axis=1, args=["Transfer"])

        dataframe.loc[dataframe["Adoption"] < 0, "Adoption"] = 0.0
        dataframe.loc[dataframe["Died"] < 0, "Died"] = 0.0
        dataframe.loc[dataframe["Euthanasia"] < 0, "Euthanasia"] = 0.0
        dataframe.loc[dataframe["Return_to_owner"] < 0, "Return_to_owner"] = 0.0
        dataframe.loc[dataframe["Transfer"] < 0, "Transfer"] = 0.0

        dataframe.loc[dataframe["Adoption"] > 1, "Adoption"] = 1.0
        dataframe.loc[dataframe["Died"] > 1, "Died"] = 1.0
        dataframe.loc[dataframe["Euthanasia"] > 1, "Euthanasia"] = 1.0
        dataframe.loc[dataframe["Return_to_owner"] > 1, "Return_to_owner"] = 1.0
        dataframe.loc[dataframe["Transfer"] > 1, "Transfer"] = 1.0

        submission = pandas.DataFrame({
            "ID": dataframe["ID"],
            "Adoption": dataframe["Adoption"],
            "Died": dataframe["Died"],
            "Euthanasia": dataframe["Euthanasia"],
            "Return_to_owner": dataframe["Return_to_owner"],
            "Transfer": dataframe["Transfer"]
        })

        submission = submission[["ID", "Adoption", "Died", "Euthanasia", "Return_to_owner", "Transfer"]]
        submission.to_csv("shelter07-09subset{0}gbrf{1}cv.csv".format(num_models, score), index=False)

def clean_data(dataframe):

    # formatting AnimalType column
    dataframe.loc[dataframe["AnimalType"] == "Dog", "AnimalType"] = 0
    dataframe.loc[dataframe["AnimalType"] == "Cat", "AnimalType"] = 1

    # filling SexuponOutcome column
    # we are filling with the most common result
    dataframe["SexuponOutcome"] = dataframe["SexuponOutcome"].fillna("Neutered Male")

    # formatting SexuponOutcome column
    dataframe.loc[dataframe["SexuponOutcome"] == "Neutered Male", "SexuponOutcome"] = 0
    dataframe.loc[dataframe["SexuponOutcome"] == "Spayed Female", "SexuponOutcome"] = 1
    dataframe.loc[dataframe["SexuponOutcome"] == "Intact Male", "SexuponOutcome"] = 2
    dataframe.loc[dataframe["SexuponOutcome"] == "Intact Female", "SexuponOutcome"] = 3
    dataframe.loc[dataframe["SexuponOutcome"] == "Unknown", "SexuponOutcome"] = 4
   
    # formatting OutcomeType column
    # only for training set
    try: 
        dataframe.loc[dataframe["OutcomeType"] == "Adoption", "OutcomeType"] = 0 
        dataframe.loc[dataframe["OutcomeType"] == "Died", "OutcomeType"] = 1
        dataframe.loc[dataframe["OutcomeType"] == "Euthanasia", "OutcomeType"] = 2
        dataframe.loc[dataframe["OutcomeType"] == "Return_to_owner", "OutcomeType"] = 3
        dataframe.loc[dataframe["OutcomeType"] == "Transfer", "OutcomeType"] = 4 
        dataframe["OutcomeType"] = dataframe["OutcomeType"].astype(int)
    except:
        pass

    # filling AgeuponOutcome column
    # we are considering that an animal with missing age has 0 years
    dataframe["AgeuponOutcome"] = dataframe["AgeuponOutcome"].fillna(0)
   
    # formatting AgeuponOutcome column
    # terrible hack, improve this later
    def get_age(animal):
        age = str(animal["AgeuponOutcome"])
        try:
            if 'week' in age:
                return 0
            elif 'month' in age:
                value = int(age.split()[0])*(-1)
                if value < -6:
                    return -6
                return value
            else:
                return age.split()[0]
        except:
            return -1

    dataframe["AgeuponOutcome"] = dataframe.apply(get_age, axis=1)
    dataframe["AgeuponOutcome"] = dataframe["AgeuponOutcome"].astype(int)
   
    # separation between Mixed and more Pure races 
    def is_mixed(animal):
        breed = animal["Breed"]
        if "Mix" in breed or "/" in breed:
            return 1
        else:
            return 0

    dataframe["Pedigree"] = dataframe.apply(is_mixed, axis=1)

    # formatting Breed column
    # can be improved, but works
    breed_mapping = {}
    def get_breed(animal):
        breed = animal["Breed"].split(",")[0]
        try:
            breed_mapping[breed] += 1
        except KeyError:
            breed_mapping[breed] = 1
        return breed_mapping[breed]    

    def apply_breed(animal):
        breed = animal["Breed"].split(",")[0]
        return breed_mapping[breed]

    dataframe.apply(get_breed, axis=1)
    dataframe['Breed'] = dataframe.apply(apply_breed, axis=1)
    dataframe.loc[dataframe["Breed"] < 100, "Breed"] = 1

    # formatting Color column
    # can be improved, but works
    color_mapping = {} 
    def get_color(animal):
        color = animal['Color'].split(",")[0]  
        try:
            color_mapping[color] += 1
        except KeyError:
            color_mapping[color] = 1 
        return color_mapping[color]    

    def apply_color(animal):
        color = animal['Color'].split(",")[0]  
        return color_mapping[color]

    dataframe.apply(get_color, axis=1)
    dataframe['Color'] = dataframe.apply(apply_color, axis=1)
    dataframe.loc[dataframe["Color"] < 100, "Color"] = 1

    def get_identity(animal):
        name = animal['Name']
        if pandas.isnull(name):
            return 0 
        else:
            return 1
    dataframe['Identity'] = dataframe.apply(get_identity, axis=1)

    dataframe.drop('Name', axis=1, inplace=True)



shelter = pandas.read_csv("train.csv")
test = pandas.read_csv("test.csv")

clean_data(shelter)
clean_data(test)

algorithms = []
for i in range(5):
    algorithms.append([GradientBoostingClassifier(random_state=i, n_estimators=35, max_depth=5), ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"]])
    algorithms.append([RandomForestClassifier(random_state=i, n_estimators=150, min_samples_split=4, min_samples_leaf=3), ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"]])

#algorithms.append([MLPClassifier(), ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"]])
#predictions = perform_SVM(shelter, shelter["OutcomeType"], test, ["AnimalType", "SexuponOutcome", "AgeuponOutcome", "Breed", "Color", "Identity", "Pedigree"])

predictions = perform_ensemble_proba_incremental(algorithms, shelter, test)


insert_probabilities_incremental(test, predictions)
