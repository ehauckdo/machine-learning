{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Exploration\n",
    "\n",
    "In this competition, we are trying to figure out the prices for which a bunch of houses have been sold.\n",
    "A lot of these features can be used out-of-the-box, so let's check what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking The Data\n",
    "\n",
    "Let's begin by first loading our training and test set and taking a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Id column won't be useful for building the model,\n",
    "# so let's make it the index of the dataframe\n",
    "train = pd.read_csv(\"input/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"input/test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our dataset has 1460 and 1459 houses on our training and test set, respectively. We have a lot of categorial features in this dataset, so it's interesting to break them into dummy variables. To make it easier for us to create and manipulate these variables, let's join the training and test set, so that both will end up with the same columns. We can split them back after we've done all the data cleaning.\n",
    "\n",
    "Note: model evaluation is based on the log of SalePrice, so we will save it as log too. We need to change it back before exporting our submission file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything, we are going to remove outliers from our training data. Later on we are going to merge training and test set to perform transformations, so it's important to deal with outliers before that (we don't want to remove any data from the test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Feature: OverralQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in range(9):\n",
    "#    temp = train.loc[train['OverallQual'] == i+1]\n",
    "    #print(temp[\"SalePrice\"], temp.shape)\n",
    "\n",
    "#    temp = temp[~(np.abs(temp.SalePrice-temp.SalePrice.mean())<=(2*temp.SalePrice.std()))]\n",
    "    #print(temp[\"SalePrice\"], temp.shape)\n",
    "\n",
    "#    train = train[~train.isin(temp)].dropna(how='all')\n",
    "#    print(i+1, train.shape)\n",
    "\n",
    "#=======10======\n",
    "temp = train.loc[train['OverallQual'] == 10]\n",
    "#print(temp[\"SalePrice\"], temp.shape)\n",
    "\n",
    "temp = temp[~(np.abs(temp.SalePrice-temp.SalePrice.mean())<=(1*temp.SalePrice.std()))]\n",
    "#print(temp[\"SalePrice\"], temp.shape)\n",
    "\n",
    "#print(train.shape)\n",
    "train = train[~train.isin(temp)].dropna(how='all')\n",
    "print(10, train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Feature: OverralCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in range(10):\n",
    "#    temp = train.loc[train['OverallCond'] == i]\n",
    "#    #print(temp[\"SalePrice\"], temp.shape)\n",
    "\n",
    "#    temp = temp[~(np.abs(temp.SalePrice-temp.SalePrice.mean())<=(2*temp.SalePrice.std()))]\n",
    "#    #print(temp[\"SalePrice\"], temp.shape)\n",
    "\n",
    "#    train = train[~train.isin(temp)].dropna(how='all')\n",
    "#    print(i, train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's remove sale prices of our train before joining, and save them for later use\n",
    "Y_train = np.log(train.pop('SalePrice'))\n",
    "\n",
    "all_df = pd.concat((train, test), axis=0)\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Transformations\n",
    "\n",
    "First thing to notice is that one of the features in the dataset, MSSubClass, is a categorical feature stored as a numeric one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df['MSSubClass'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df['MSSubClass'] = all_df['MSSubClass'].apply(str)\n",
    "all_df['MSSubClass'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These transformations were made by Boris Klyus on a Kaggle notebook. Here he is simply changing all categorical (and some numerical) features that comes with NaN values to a more informative label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df.loc[all_df.Alley.isnull(), 'Alley'] = 'NoAlley'\n",
    "all_df.loc[all_df.MasVnrType.isnull(), 'MasVnrType'] = 'None' # no good\n",
    "all_df.loc[all_df.MasVnrType == 'None', 'MasVnrArea'] = 0\n",
    "all_df.loc[all_df.BsmtQual.isnull(), 'BsmtQual'] = 'NoBsmt'\n",
    "all_df.loc[all_df.BsmtCond.isnull(), 'BsmtCond'] = 'NoBsmt'\n",
    "all_df.loc[all_df.BsmtExposure.isnull(), 'BsmtExposure'] = 'NoBsmt'\n",
    "all_df.loc[all_df.BsmtFinType1.isnull(), 'BsmtFinType1'] = 'NoBsmt'\n",
    "all_df.loc[all_df.BsmtFinType2.isnull(), 'BsmtFinType2'] = 'NoBsmt'\n",
    "all_df.loc[all_df.BsmtFinType1=='NoBsmt', 'BsmtFinSF1'] = 0\n",
    "all_df.loc[all_df.BsmtFinType2=='NoBsmt', 'BsmtFinSF2'] = 0\n",
    "all_df.loc[all_df.BsmtFinSF1.isnull(), 'BsmtFinSF1'] = all_df.BsmtFinSF1.median()\n",
    "all_df.loc[all_df.BsmtQual=='NoBsmt', 'BsmtUnfSF'] = 0\n",
    "all_df.loc[all_df.BsmtUnfSF.isnull(), 'BsmtUnfSF'] = all_df.BsmtUnfSF.median()\n",
    "all_df.loc[all_df.BsmtQual=='NoBsmt', 'TotalBsmtSF'] = 0\n",
    "all_df.loc[all_df.FireplaceQu.isnull(), 'FireplaceQu'] = 'NoFireplace'\n",
    "all_df.loc[all_df.GarageType.isnull(), 'GarageType'] = 'NoGarage'\n",
    "all_df.loc[all_df.GarageFinish.isnull(), 'GarageFinish'] = 'NoGarage'\n",
    "all_df.loc[all_df.GarageQual.isnull(), 'GarageQual'] = 'NoGarage'\n",
    "all_df.loc[all_df.GarageCond.isnull(), 'GarageCond'] = 'NoGarage'\n",
    "all_df.loc[all_df.BsmtFullBath.isnull(), 'BsmtFullBath'] = 0\n",
    "all_df.loc[all_df.BsmtHalfBath.isnull(), 'BsmtHalfBath'] = 0\n",
    "all_df.loc[all_df.KitchenQual.isnull(), 'KitchenQual'] = 'TA'\n",
    "all_df.loc[all_df.MSZoning.isnull(), 'MSZoning'] = 'RL'\n",
    "all_df.loc[all_df.Utilities.isnull(), 'Utilities'] = 'AllPub'\n",
    "all_df.loc[all_df.Exterior1st.isnull(), 'Exterior1st'] = 'VinylSd'\n",
    "all_df.loc[all_df.Exterior2nd.isnull(), 'Exterior2nd'] = 'VinylSd'\n",
    "all_df.loc[all_df.Functional.isnull(), 'Functional'] = 'Typ'\n",
    "all_df.loc[all_df.SaleCondition.isnull(), 'SaleCondition'] = 'Normal'\n",
    "all_df.loc[all_df.SaleCondition.isnull(), 'SaleType'] = 'WD'\n",
    "all_df.loc[all_df['PoolQC'].isnull(), 'PoolQC'] = 'NoPool'\n",
    "all_df.loc[all_df['Fence'].isnull(), 'Fence'] = 'NoFence'\n",
    "all_df.loc[all_df['MiscFeature'].isnull(), 'MiscFeature'] = 'None'\n",
    "all_df.loc[all_df['Electrical'].isnull(), 'Electrical'] = 'SBrkr'\n",
    "# only one is null and it has type Detchd\n",
    "all_df.loc[all_df['GarageArea'].isnull(), 'GarageArea'] = all_df.loc[all_df['GarageType']=='Detchd', 'GarageArea'].mean()\n",
    "all_df.loc[all_df['GarageCars'].isnull(), 'GarageCars'] = all_df.loc[all_df['GarageType']=='Detchd', 'GarageCars'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dummy variables\n",
    "\n",
    "Now that we have everything together, we need to generate dummy variables for our categorical features. Pandas can help us with the get_dummy_variable function. It generates dummy variables for a series or an entire dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dummy_df = pd.get_dummies(all_df)\n",
    "\n",
    "# let's check if everything went alright\n",
    "all_dummy_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Column order looks a little messy. They are in alphabetical order now, but that shouldn't be a problem. But we do have a lot of columns, which is possibly a bigger deal to be worried with.\n",
    "\n",
    "Now that we have our dummy variables, we should check for NaN values in our columns. For the categorical features, pandas' get_dummy_variables takes care of this for us. For example, for a feature X which could get values a, b or c, if an individual has NaN for X, all 3 resulting columns (X_a, X_b, X_c) will be assigned 0. (Note: it can be useful to create a new column for missing values, e.g., X_missing, because not being assigned to any label could be informative; we should get back at this later)\n",
    "\n",
    "## Missing Values\n",
    "\n",
    "Since there's no missing values for our categorical features, we just need to check the numerical ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dummy_df.isnull().sum().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take care of these missing values. For now, let's just assign the mean for all missing values. There's probably better ways to deal with that, but let's just do the easy way now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_columns = all_dummy_df.mean()\n",
    "all_dummy_df = all_dummy_df.fillna(mean_columns)\n",
    "\n",
    "all_dummy_df.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x = train['OverallQual'], y = np.exp(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x = train['YearBuilt'], y = np.exp(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x = train['OverallCond'], y = np.exp(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x = train['GrLivArea'], y = np.exp(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize numerical features\n",
    "\n",
    "Since we are going to do regression on this dataset, it's recommended to standardize our numerical features. So we are going to get all numerical features, subtract by the mean and divide by the standard deviation. This will make them all scaled similarly.\n",
    "\n",
    "First let's break our dataset into train and test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_train_df = all_dummy_df.loc[train.index]\n",
    "dummy_test_df = all_dummy_df.loc[test.index]\n",
    "\n",
    "dummy_train_df.shape, dummy_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get our numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_cols = all_df.columns[all_df.dtypes != 'object']\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the normalization both on our train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_numeric_col_means = dummy_train_df.loc[:, numeric_cols].mean()\n",
    "train_numeric_col_std = dummy_train_df.loc[:, numeric_cols].std()\n",
    "\n",
    "dummy_train_df.loc[:, numeric_cols] = (dummy_train_df.loc[:, numeric_cols] - train_numeric_col_means) / train_numeric_col_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_numeric_col_means = dummy_test_df.loc[:, numeric_cols].mean()\n",
    "test_numeric_col_std = dummy_test_df.loc[:, numeric_cols].std()\n",
    "\n",
    "dummy_test_df.loc[:, numeric_cols] = (dummy_test_df.loc[:, numeric_cols] - test_numeric_col_means) / test_numeric_col_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the histogram of a variable to see if everything went alright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_train_df['GrLivArea'].hist(), dummy_test_df['GrLivArea'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers but we are going to just leave it like that for now.\n",
    "\n",
    "And this is all the data preparation we need. There's still a lot of things that could be done, but let just proceed for building the model and checking how well we can do with this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Model\n",
    "\n",
    "Let's try building some models now. I'll just try some available in sklearn library and see what works best. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = list(dummy_train_df.describe().columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have everything prepared, we are going to follow some steps for each regressor we are going to use.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1 - find the most relevant/important features for the model\\* <br />\n",
    "2 - tune the hyper-parameters <br />\n",
    "3 - cross validate the model on our training data \n",
    "\n",
    "\\*This step will vary depending on the regressor. Tree-based regressor have a built-in feature_importances field which we can use to get the most relevant features. For other approach-based regressors, we are going to use the SelectKBest class to get the most relevant features of our dataset for doing regression on the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Finding the best features\n",
    "\n",
    "As mentioned, the way to select features depends on the regressor. Here, we are going to have two approaches, each one defining a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are going to use this function for tree-based regressors\n",
    "def get_best_threshold(regressor, X, Y, initial_threshold=0.1, limit_features=100, threshold_increase=-0.0001, title=\"\"):\n",
    "\n",
    "    base = np.sqrt(-cross_val_score(regressor, X, Y, cv=10, scoring='neg_mean_squared_error'))\n",
    "    sfm = SelectFromModel(regressor, threshold=initial_threshold)\n",
    "\n",
    "    n_features = sfm.fit_transform(X, Y).shape[1]\n",
    "    last_n_features = n_features\n",
    "    threshold_results = []\n",
    "    \n",
    "    f = open(\"output/{0}.txt\".format(title),\"w\")\n",
    "    f.write(\"Result: {0}, N_features: All\\n\".format(np.mean(base)))\n",
    "    \n",
    "    while n_features < limit_features:\n",
    "        sfm.threshold += threshold_increase\n",
    "        X_new = sfm.fit_transform(X, Y)\n",
    "        n_features = X_new.shape[1]\n",
    "\n",
    "        if n_features > last_n_features:\n",
    "            \n",
    "            last_n_features = n_features\n",
    "            selected_features_score = np.sqrt(-cross_val_score(regressor, X_new, Y, cv=5, scoring='neg_mean_squared_error'))\n",
    "            f.write(\"Result: {0}, Threshold: {1}, N_features: {2}\\n\".format(np.mean(selected_features_score), sfm.threshold, n_features))\n",
    "            threshold_results.append((sfm.threshold, np.mean(selected_features_score)))\n",
    "            \n",
    "    better_threshold = min(threshold_results, key = itemgetter(1))[0]\n",
    "    f.close()\n",
    "    return better_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are going to use this function for non-tree-based regressors\n",
    "def get_best_features(regressor, X, Y, limit_features=100, feature_increase=3, title=\"\"):\n",
    "\n",
    "    k_features = 10\n",
    "    k_features_results = []\n",
    "    f = open(\"output/{0}.txt\".format(title),\"w\")\n",
    "\n",
    "    # use SelectKBest to iterate over important features\n",
    "    while k_features < limit_features:\n",
    "        selector = SelectKBest(f_regression, k=k_features)\n",
    "        X_new = selector.fit_transform(X, Y)\n",
    "        selected_features_score = np.sqrt(-cross_val_score(regressor, X_new, Y, cv=8, scoring='neg_mean_squared_error'))\n",
    "        f.write(\"Result: {0}, Variance: {1}, N_features: {2}\\n\".format(np.mean(selected_features_score),\n",
    "                                                                       np.var(selected_features_score), k_features))\n",
    "        k_features_results.append((k_features, np.mean(selected_features_score)))\n",
    "        k_features += feature_increase\n",
    "        \n",
    "    f.close()\n",
    "    best_k_features = min(k_features_results, key = itemgetter(1))[0]\n",
    "    return best_k_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Tuning the hyper-parameters\n",
    "\n",
    "Here we are going to use sklearn's GridSearchCV to exhaustively search a for the best params in a dictionary. You need to pass it values to be tested. If you don't don't know which range of values to use for a parameter, an idea is to check the default value, and work from there. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hyper_parameters(alg, parameters, X, Y, title=\"GridSearch\"):\n",
    "    \n",
    "    f = open(\"output/{0}.txt\".format(title),\"w\")\n",
    "    gs = GridSearchCV(alg, parameters, n_jobs=3, cv=5)                \n",
    "    gs.fit(X, Y)\n",
    "    for param in gs.best_params_.keys():\n",
    "        f.write(\"Param: {0},  Value: {1}\\n\".format(param, gs.best_params_[param]))\n",
    "    f.close()\n",
    "        \n",
    "    return gs.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Cross-validating\n",
    "\n",
    "We don't have any code for this, it will be done after we build the model. One important thing to notice is the number of CV folds to use, and the scorer parameter. Here we are going to use the 'neg_mean_squared_error' because this is the scoring function which Kaggle will validate your results, so it's good to have similar score range while cross-validating, so we can have an idea how well we are going to do on the leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some of these parameters have already been tuned\n",
    "# we are going to declare them here so we don't have\n",
    "# grid search everytime we run this notebook\n",
    "\n",
    "RF_data = {\n",
    "    #all features                   #selected features\n",
    "    'n_estimators':       300,     'n_estimators_all':      300,   \n",
    "    'max_features':       0.5,     'max_features_all':       0.2,  \n",
    "    'min_samples_leaf':   1,       'min_samples_leaf_all':   1,\n",
    "    'min_samples_split':  1,       'min_samples_split_all':  4,\n",
    "    'max_depth':          None,    'max_depth_all':          None,\n",
    "    'best_threshold':     0.0036\n",
    "}\n",
    "\n",
    "GB_data = {\n",
    "    #all features                  #selected features\n",
    "    'n_estimators':       300,     'n_estimators_all':       300,    \n",
    "    'max_features':       'sqrt',  'max_features_all':       'sqrt',     \n",
    "    'min_samples_leaf':   1,       'min_samples_leaf_all':   1,\n",
    "    'min_samples_split':  1,       'min_samples_split_all':  1,\n",
    "    'max_depth':          3,       'max_depth_all':          3,         \n",
    "    'learning_rate':      0.1,     'learning_rate_all':      0.1, \n",
    "    'best_threshold':     0.0024\n",
    "}\n",
    "\n",
    "RR_data = {\n",
    "    #'alpha': 0.568986602902,                   'alpha_all': 0.449843266897,     # normalize = true\n",
    "    'alpha': 9.5409547635,                      'alpha_all': 15.2641796718,       # normalize = false\n",
    "    'best_n_features': 156,  \n",
    "}\n",
    "\n",
    "EN_data = {\n",
    "    #'alpha': 0.568986602902,                   'alpha_all': 0.449843266897,     # normalize = true\n",
    "    'alpha': 9.5409547635,                      'alpha_all': 15.2641796718,       # normalize = false\n",
    "    'best_n_features': 173,  \n",
    "}\n",
    "\n",
    "XGB_data = {\n",
    "    'n_estimators':       100,\n",
    "    'learning_rate':      0.1,\n",
    "    'best_n_features' :   300,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble.forest import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alg = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# First step: get the best features for our train and test\n",
    "# this step was previously done so we can skip it\n",
    "#best_threshold = get_best_threshold(alg, dummy_train_df[all_features], Y_train, title=\"RF_threshold\")\n",
    "#RF_data['best_threshold'] = best_threshold\n",
    "\n",
    "sfm = SelectFromModel(alg, threshold=RF_data['best_threshold'])\n",
    "X_train_new = sfm.fit_transform(dummy_train_df[all_features], Y_train)\n",
    "X_test_new = sfm.transform(dummy_test_df[all_features])\n",
    "\n",
    "# Second step: grid search for the best params\n",
    "# this step was previously done so we can skip it\n",
    "#parameters = {\n",
    "#    'n_estimators' : [5, 10, 25, 40, 65, 80, 100, 150, 200, 300],\n",
    "#    'max_features' : [\"auto\", \"sqrt\", \"log2\", 0.2, 0.5],\n",
    "#    'min_samples_leaf' : [1, 5, 10, 25, 50],\n",
    "#    'min_samples_split' : [1, 2, 4, 8] ,\n",
    "#    'max_depth': [None, 3, 5, 10]\n",
    "#    }\n",
    "\n",
    "#bp = get_hyper_parameters(alg, parameters, X_train_new, Y_train, \"RF_grid_selected\")\n",
    "#bp2 = get_hyper_parameters(alg, parameters, dummy_train_df[all_features], Y_train, \"RF_grid_all\")\n",
    "#let's store this information for later use\n",
    "#RF_data['n_estimators'] = bp['n_estimators']\n",
    "#RF_data['max_features'] = bp['max_features']\n",
    "#RF_data['min_samples_split'] = bp['min_samples_split']\n",
    "#RF_data['min_samples_leaf'] = bp['min_samples_leaf']\n",
    "#RF_data['max_depth'] = bp['max_depth']\n",
    "\n",
    "# Third step: cross-validate, here we compare the cross-validated\n",
    "# scores both using all the features and just the selected features\n",
    "regr_selected = RandomForestRegressor(random_state=1, n_estimators=RF_data['n_estimators'], max_features=RF_data['max_features'],\n",
    "                            min_samples_split=RF_data['min_samples_split'], min_samples_leaf=RF_data['min_samples_leaf'],\n",
    "                            max_depth=RF_data['max_depth'])\n",
    "regr_all = RandomForestRegressor(random_state=1, n_estimators=RF_data['n_estimators_all'], \n",
    "                            max_features=RF_data['max_features_all'], min_samples_split=RF_data['min_samples_split_all'], \n",
    "                            min_samples_leaf=RF_data['min_samples_leaf_all'], max_depth=RF_data['max_depth_all'])\n",
    "\n",
    "selected_features_score = np.sqrt(-cross_val_score(regr_selected, X_train_new, Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "all_features_score = np.sqrt(-cross_val_score(regr_all, dummy_train_df[all_features], Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "\n",
    "selected_features_score = np.mean(selected_features_score)\n",
    "all_features_score = np.mean(all_features_score)\n",
    "\n",
    "# Last step: run our model and generate submission files\n",
    "submission =  pd.DataFrame()\n",
    "submission[\"Id\"] = test.index\n",
    "\n",
    "regr_all.fit(dummy_train_df[all_features], Y_train)\n",
    "predictions = regr_all.predict(dummy_test_df)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/rf_whole_submission.csv\", index=False)\n",
    "\n",
    "regr_selected.fit(X_train_new, Y_train)\n",
    "predictions = regr_selected.predict(X_test_new)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/rf_subset_submission.csv\", index=False)\n",
    "\n",
    "np.mean(selected_features_score), np.mean(all_features_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's seems that selecting the best features gives us just slightly better results than just using all the generated features. As expected the impact is not so big for tree based approaches, but it should be worth repeating this test for regressors with different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = GradientBoostingRegressor(random_state=1)\n",
    "\n",
    "# First step: get the best features for our train and test\n",
    "# this step was previously done so we can skip it\n",
    "#best_threshold = get_best_threshold(alg, dummy_train_df[all_features], Y_train, title=\"GB_threshold\")\n",
    "#GB_data['best_threshold'] = best_threshold\n",
    "\n",
    "sfm = SelectFromModel(alg, threshold=GB_data['best_threshold'])\n",
    "X_train_new = sfm.fit_transform(dummy_train_df[all_features], Y_train)\n",
    "X_test_new = sfm.transform(dummy_test_df[all_features])\n",
    "\n",
    "# Second step: grid search for the best params\n",
    "# this step was previously done so we can skip it\n",
    "#parameters = {\n",
    "#    'n_estimators' : [5, 10, 25, 40, 65, 80, 100, 150, 200, 300],\n",
    "#    'max_features' : [\"auto\", \"sqrt\", \"log2\", 0.2, 0.5],\n",
    "#    'min_samples_leaf' : [1, 5, 10, 25, 50],\n",
    "#    'min_samples_split' : [1, 2, 4, 8],\n",
    "#    'max_depth': [None, 3, 5, 10],\n",
    "#    'learning_rate' : [0.05, 0.08, 0.1, 0.15, 0.2]\n",
    "#    }\n",
    "#\n",
    "#bp = get_hyper_parameters(alg, parameters, X_train_new, Y_train, \"GB_grid_selected\")\n",
    "#bp = get_hyper_parameters(alg, parameters, X_train_new, Y_train, \"GB_grid_all\")\n",
    "#let's store this information for later use\n",
    "#GB_data['n_estimators'] = bp['n_estimators']\n",
    "#GB_data['max_features'] = bp['max_features']\n",
    "#GB_data['min_samples_split'] = bp['min_samples_split']\n",
    "#GB_data['min_samples_leaf'] = bp['min_samples_leaf']\n",
    "#GB_data['max_depth'] = bp['max_depth']\n",
    "#GB_data['learning_rate'] = bp['learning_rate']\n",
    "\n",
    "# Third step: cross-validate, here we compare the cross-validated\n",
    "# scores both using all the features and just the selected features\n",
    "regr_selected = GradientBoostingRegressor(random_state=1, n_estimators=GB_data['n_estimators'], \n",
    "                                max_features=GB_data['max_features'], min_samples_split=GB_data['min_samples_split'], \n",
    "                                min_samples_leaf=GB_data['min_samples_leaf'], learning_rate=GB_data['learning_rate'])\n",
    "regr_all = GradientBoostingRegressor(random_state=1, n_estimators=GB_data['n_estimators_all'], \n",
    "                                max_features=GB_data['max_features_all'], \n",
    "                                min_samples_split=GB_data['min_samples_split_all'], \n",
    "                                min_samples_leaf=GB_data['min_samples_leaf_all'], \n",
    "                                learning_rate=GB_data['learning_rate_all'])\n",
    "\n",
    "selected_features_score = np.sqrt(-cross_val_score(regr_selected, X_train_new, Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "all_features_score = np.sqrt(-cross_val_score(regr_all, dummy_train_df[all_features], Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Last step: run our model and generate submission files\n",
    "submission =  pd.DataFrame()\n",
    "submission[\"Id\"] = test.index\n",
    "\n",
    "regr_all.fit(dummy_train_df[all_features], Y_train)\n",
    "predictions = regr_all.predict(dummy_test_df)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/gb_whole_submission.csv\", index=False)\n",
    "\n",
    "regr_selected.fit(X_train_new, Y_train)\n",
    "predictions = regr_selected.predict(X_test_new)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/gb_subset_submission.csv\", index=False)\n",
    "\n",
    "np.mean(selected_features_score), np.mean(all_features_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = Ridge(random_state=1)\n",
    "\n",
    "# First step: get the best features for our train and test\n",
    "# this step was previously done so we can skip it\n",
    "#best_n_features = get_best_features(alg, dummy_train_df[all_features], Y_train, len(all_features)+1, 1, title=\"RR_threshold\")\n",
    "#RR_data['best_n_features'] = best_n_features\n",
    "\n",
    "selector = SelectKBest(f_regression, k=RR_data['best_n_features'])\n",
    "X_train_new = selector.fit_transform(dummy_train_df[all_features], Y_train)\n",
    "X_test_new = selector.transform(dummy_test_df[all_features])\n",
    "\n",
    "# Second step: grid search for the best params\n",
    "# this step was previously done so we can skip it\n",
    "parameters = {\n",
    "'alpha' : np.logspace(-3, 2, 50),\n",
    "}\n",
    "#\n",
    "RR_data['alpha'] = get_hyper_parameters(alg, parameters, X_train_new, Y_train, \"RR_grid_selected\")['alpha']\n",
    "RR_data['alpha_all'] = get_hyper_parameters(alg, parameters, dummy_train_df[all_features], Y_train, \"RR_grid_all\")['alpha']\n",
    "\n",
    "# Third step: cross-validate, here we compare the cross-validated\n",
    "# scores both using all the features and just the selected features\n",
    "regr_selected = Ridge(random_state=1, alpha=RR_data['alpha'])\n",
    "regr_all = Ridge(random_state=1, alpha=RR_data['alpha_all'])\n",
    "          \n",
    "selected_features_score = np.sqrt(-cross_val_score(regr_selected, X_train_new, Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "all_features_score = np.sqrt(-cross_val_score(regr_all, dummy_train_df[all_features], Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Last step: run our model and generate submission files\n",
    "submission =  pd.DataFrame()\n",
    "submission[\"Id\"] = test.index\n",
    "\n",
    "regr_all.fit(dummy_train_df[all_features], Y_train)\n",
    "predictions = regr_all.predict(dummy_test_df)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/ridge_whole_submission.csv\", index=False)\n",
    "\n",
    "regr_selected.fit(X_train_new, Y_train)\n",
    "predictions = regr_selected.predict(X_test_new)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/ridge_subset_submission.csv\", index=False)\n",
    "\n",
    "print(RR_data['best_n_features'])\n",
    "np.mean(selected_features_score), np.mean(all_features_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = ElasticNet(random_state=1,  alpha=EN_data['alpha'], normalize=True)\n",
    "\n",
    "# First step: get the best features for our train and test\n",
    "# this step was previously done so we can skip it\n",
    "#best_n_features = get_best_features(alg, dummy_train_df[all_features], Y_train, len(all_features)+1, 1, title=\"EN_threshold\")\n",
    "#EN_data['best_n_features'] = best_n_features\n",
    "\n",
    "selector = SelectKBest(f_regression, k=EN_data['best_n_features'])\n",
    "X_train_new = selector.fit_transform(dummy_train_df[all_features], Y_train)\n",
    "X_test_new = selector.transform(dummy_test_df[all_features])\n",
    "\n",
    "# Second step: grid search for the best params\n",
    "# this step was previously done so we can skip it\n",
    "parameters = {\n",
    "'alpha' : np.logspace(-3, 2, 50),\n",
    "'l1_ratio' : np.arange(0.5,0.8,0.1)\n",
    "}\n",
    "#\n",
    "bp1 = get_hyper_parameters(alg, parameters, X_train_new, Y_train, \"EN_grid_selected\")\n",
    "bp2 = get_hyper_parameters(alg, parameters, dummy_train_df[all_features], Y_train, \"EN_grid_all\")\n",
    "EN_data['alpha'] = bp1['alpha']\n",
    "EN_data['alpha_all'] = bp2['alpha']\n",
    "EN_data['l1_ratio'] = bp1['l1_ratio']\n",
    "EN_data['l1_ratio_all'] = bp2['l1_ratio']\n",
    "\n",
    "# Third step: cross-validate, here we compare the cross-validated\n",
    "# scores both using all the features and just the selected features\n",
    "regr_selected = ElasticNet(random_state=1, alpha=EN_data['alpha'], l1_ratio=EN_data['l1_ratio'], normalize=True)\n",
    "regr_all = ElasticNet(random_state=1, alpha=EN_data['alpha_all'], l1_ratio=EN_data['l1_ratio_all'],normalize=True)\n",
    "          \n",
    "selected_features_score = np.sqrt(-cross_val_score(regr_selected, X_train_new, Y_train, cv=50, scoring='neg_mean_squared_error'))\n",
    "all_features_score = np.sqrt(-cross_val_score(regr_all, dummy_train_df[all_features], Y_train, cv=50, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Last step: run our model and generate submission files\n",
    "submission =  pd.DataFrame()\n",
    "submission[\"Id\"] = test.index\n",
    "\n",
    "regr_all.fit(dummy_train_df[all_features], Y_train)\n",
    "predictions = regr_all.predict(dummy_test_df)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/elasticnet_whole_submission.csv\", index=False)\n",
    "\n",
    "regr_selected.fit(X_train_new, Y_train)\n",
    "predictions = regr_selected.predict(X_test_new)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/elasticnet_subset_submission.csv\", index=False)\n",
    "\n",
    "print(EN_data['best_n_features'])\n",
    "print(EN_data['l1_ratio'])\n",
    "print(EN_data['l1_ratio_all'])\n",
    "np.mean(selected_features_score), np.mean(all_features_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = xgb.XGBRegressor(seed=0, nthread=3, n_estimators=XGB_data['n_estimators'],\n",
    "                                learning_rate=XGB_data['learning_rate'])\n",
    "\n",
    "# First step: get the best features for our train and test\n",
    "# this step was previously done so we can skip it\n",
    "#best_threshold = get_best_features(alg, dummy_train_df[all_features], Y_train, len(all_features)+1, title=\"XGB_threshold\")\n",
    "#XGB_data['best_threshold'] = best_threshold\n",
    "\n",
    "selector = SelectKBest(f_regression, k=XGB_data['best_n_features'])\n",
    "X_train_new = selector.fit_transform(dummy_train_df[all_features], Y_train)\n",
    "X_test_new = selector.transform(dummy_test_df[all_features])\n",
    "\n",
    "# Second step: grid search for the best params\n",
    "# this step was previously done so we can skip it\n",
    "#parameters = {\n",
    "#    'n_estimators' : [5, 10, 25, 40, 65, 80, 100, 150, 200, 300],\n",
    "#    'min_samples_leaf' : [1, 5, 10, 25, 50],\n",
    "#    'min_samples_split' : [1, 2, 4, 8],\n",
    "#    'max_depth': [None, 3, 5, 10],\n",
    "#    'learning_rate' : [0.05, 0.08, 0.1, 0.15, 0.2]\n",
    "#    }\n",
    "#\n",
    "#bp = get_hyper_parameters(alg, parameters, X_train_new, Y_train, \"XGB_grid_selected\")\n",
    "#bp = get_hyper_parameters(alg, parameters,  dummy_train_df[all_features], Y_train, \"XGB_grid_all\")\n",
    "\n",
    "# Third step: cross-validate, here we compare the cross-validated\n",
    "# scores both using all the features and just the selected features\n",
    "regr = xgb.XGBRegressor(seed=0, nthread=3, n_estimators=XGB_data['n_estimators'],\n",
    "                                learning_rate=XGB_data['learning_rate'])\n",
    "\n",
    "selected_features_score = np.sqrt(-cross_val_score(regr, X_train_new, Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "all_features_score = np.sqrt(-cross_val_score(regr, dummy_train_df[all_features], Y_train, cv=8, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Last step: run our model and generate submission files\n",
    "submission =  pd.DataFrame()\n",
    "submission[\"Id\"] = test.index\n",
    "\n",
    "regr.fit(dummy_train_df[all_features], Y_train)\n",
    "predictions = regr.predict(dummy_test_df)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/xgb_whole_submission.csv\", index=False)\n",
    "\n",
    "regr.fit(X_train_new, Y_train)\n",
    "predictions = regr.predict(X_test_new)\n",
    "submission[\"SalePrice\"] = np.exp(predictions)\n",
    "submission.to_csv(\"output/xgb_subset_submission.csv\", index=False)\n",
    "\n",
    "np.mean(selected_features_score), np.mean(all_features_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alg = MLPRegressor(random_state=1)\n",
    "#\n",
    "#best_features = get_best_features(alg, dummy_train_df[all_features], Y_train, 100, 3)\n",
    "#          \n",
    "#selector = SelectKBest(f_regression, k=best_features)\n",
    "#X_train_new = selector.fit_transform(dummy_train_df[all_features], Y_train)\n",
    "#X_test_new = selector.transform(dummy_test_df[all_features])\n",
    "#          \n",
    "#now let's try comparing the selected KBest features with all features\n",
    "#selected_features_score = np.sqrt(-cross_val_score(alg, X_train_new, Y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "#all_features_score = np.sqrt(-cross_val_score(alg, dummy_train_df[all_features], Y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "#\n",
    "#np.mean(selected_features_score), np.mean(all_features_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Multi-Layer Perceptron it seems that having many features just make it worse. Using only the overall quality of the house as a feature wields the best result, which is far from good by the way. For now, let's just be done with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#alg = SVR()\n",
    "#alg = SVR(epsilon=0, C=2, gamma=3.0517578125e-05)\n",
    "#\n",
    "#best_features = get_best_features(alg, dummy_train_df[all_features], Y_train, 100, 3)\n",
    "#          \n",
    "#selector = SelectKBest(f_regression, k=best_features)\n",
    "#X_train_new = selector.fit_transform(dummy_train_df[all_features], Y_train)\n",
    "#X_test_new = selector.transform(dummy_test_df[all_features])\n",
    "#\n",
    "#parameters = {   \n",
    "#    'C' : [2**i for i in range(-5,15, 2)], # 2^-5, 2^-3,..., 2^15\n",
    "#    'gamma' : [2**i for i in range(-15,3, 2)], # 2^-15, 2^-13,..., 2^3\n",
    "#    'epsilon' : [0, 0.01, 0.1, 0.5, 1, 2, 4]\n",
    "#}    \n",
    "#\n",
    "#bp = get_hyper_parameters(alg, parameters, X_train_new, Y_train)\n",
    "#alg = SVR(epsilon=bp['epsilon'], C=bp['C'], gamma=bp['gamma'])\n",
    "#    \n",
    "#now let's try comparing the selected KBest features with all features\n",
    "#selected_features_score = np.sqrt(-cross_val_score(alg, X_train_new, Y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "#all_features_score = np.sqrt(-cross_val_score(alg, dummy_train_df[all_features], Y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "#\n",
    "#np.mean(selected_features_score), np.mean(all_features_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same reasoning for MLP goes for SVR, using many features is not very helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we will pass a list of regressors and this function \n",
    "# will perform the ensemble for us\n",
    "def perform_ensemble(regressors, train, target, test, subset_size=0.8):\n",
    "    total_predictions = []\n",
    "    total_scores = []\n",
    "    seeds = []\n",
    "    for alg in regressors:\n",
    "        train[\"SalePrice\"] = target\n",
    "        random_state = alg.get_params()[\"random_state\"]\n",
    "        subset = train.sample(frac=subset_size, random_state=random_state)\n",
    "        subset_target = subset.pop(\"SalePrice\")\n",
    "        \n",
    "        score = np.sqrt(-cross_val_score(alg, subset, subset_target, cv=8, scoring='neg_mean_squared_error'))\n",
    "        if not total_scores or np.mean(score) < np.mean(total_scores):\n",
    "            total_scores.append(score)\n",
    "            print(\"{0}: Mean: {1} (New score: {2}, seed: {3})\".format(len(total_predictions), \n",
    "                                                        np.mean(total_scores), np.mean(score), random_state))\n",
    "        \n",
    "            alg.fit(subset, subset_target)\n",
    "            prediction = alg.predict(test)\n",
    "            total_predictions.append(prediction)\n",
    "\n",
    "    # average scores\n",
    "    return np.mean(total_predictions, axis=0)\n",
    "\n",
    "\n",
    "regressors = []\n",
    "for i in range(20):\n",
    "    seed = i #np.random.randint(4294967295)\n",
    "    regressors.append(Ridge(random_state=seed, alpha=RR_data['alpha_all']))\n",
    "#regressors.append(Ridge(random_state=1, alpha=RR_data['alpha_all']))\n",
    "#regressors.append(RandomForestRegressor(random_state=1, n_estimators=RF_data['n_estimators_all'], \n",
    "#                            max_features=RF_data['max_features_all'], min_samples_split=RF_data['min_samples_split_all'], \n",
    "#                            min_samples_leaf=RF_data['min_samples_leaf_all'], max_depth=RF_data['max_depth_all']))\n",
    "#regressors.append(GradientBoostingRegressor(random_state=1, n_estimators=GB_data['n_estimators_all'], \n",
    "#                                max_features=GB_data['max_features_all'], \n",
    "#                                min_samples_split=GB_data['min_samples_split_all'], \n",
    "#                                min_samples_leaf=GB_data['min_samples_leaf_all'], \n",
    "#                                learning_rate=GB_data['learning_rate_all']))\n",
    "result = perform_ensemble(regressors, dummy_train_df[all_features], Y_train, dummy_test_df)\n",
    "\n",
    "submission =  pd.DataFrame()\n",
    "submission[\"Id\"] = test.index\n",
    "\n",
    "submission[\"SalePrice\"] = np.exp(result)\n",
    "submission.to_csv(\"output/ensemble_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reference Links\n",
    "\n",
    "[Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project (read this for insights on the dataset)](https://ww2.amstat.org/publications/jse/v19n3/decock.pdf)\n",
    "\n",
    "[How to Tune Algorithm Parameters with Scikit-Learn](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)\n",
    "\n",
    "[Parameter Tuning in Gradient Boosting (GBM) in Python](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/)\n",
    "\n",
    "[Ridge and Lasso tutorial](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n",
    "\n",
    "[Tuning the parameters of your Random Forest model](https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/)\n",
    "\n",
    "[Ensemble Modeling: Stack Model Example](https://www.kaggle.com/jimthompson/house-prices-advanced-regression-techniques/ensemble-model-stacked-model-example/discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
