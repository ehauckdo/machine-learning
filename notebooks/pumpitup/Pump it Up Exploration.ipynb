{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump it Up: Data Mining the Water Table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition, we are trying to predict which water pumps are functional in some places in Tanzania. This competition is hosted by DrivenData[Add link] and the dataset is provided Taarifa[Add link] and the Tanzanian Ministry of Water[Add link]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"input/train.csv\",index_col=0)\n",
    "test = pd.read_csv(\"input/test.csv\",index_col=0)\n",
    "train_labels = pd.read_csv(\"input/train_labels.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train = pd.merge(train, train_labels, left_on=\"id\", right_on=\"id\")\n",
    "all_df = pd.concat((train, test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 39), (14850, 39), (74250, 39))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tNull checking, let's take care of these values\n",
    "#train.isnull().sum().sort_values(ascending=False).head(8)\n",
    "#test.isnull().sum().sort_values(ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df.replace(['Not Known'], ['unkown'], inplace=True)\n",
    "all_df.loc[all_df.scheme_name.isnull(), 'scheme_name'] = 'unknown'\n",
    "all_df.loc[all_df.scheme_management.isnull(), 'scheme_management'] = 'unknown'\n",
    "all_df.loc[all_df.funder.isnull(), 'funder'] = 'unknown'\n",
    "all_df.loc[all_df.installer.isnull(), 'installer'] = 'unknown'\n",
    "all_df.loc[all_df.subvillage.isnull(), 'subvillage'] = 'unknown'\n",
    "all_df.loc[all_df.public_meeting.isnull(), 'public_meeting'] = False\n",
    "all_df.loc[all_df.permit.isnull(), 'permit'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "waterpoint_type_group    0\n",
       "basin                    0\n",
       "population               0\n",
       "ward                     0\n",
       "lga                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.isnull().sum().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing features\n",
    "\n",
    "### Deleting unused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74250, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# height, longitude and latitute demand more processing, do it later\n",
    "exclude_features = [\"longitude\", \"latitude\"]\n",
    "all_df = all_df.drop(exclude_features, 1)\n",
    "all_df.shape\n",
    "\n",
    "# these features are duplicated in the dataset (there are other features with exact same values)\n",
    "duplicated_features = [\"payment\", \"quantity\"]\n",
    "all_df = all_df.drop(duplicated_features, 1)\n",
    "all_df.shape\n",
    "\n",
    "# these features are redundant in the data set (there are other features that explain it better)\n",
    "redundant_features = [\"source_type\", \"waterpoint_type_group\"]\n",
    "all_df = all_df.drop(redundant_features, 1)\n",
    "all_df.shape\n",
    "\n",
    "# these features only have 1 value for all rows\n",
    "unused_features = [\"recorded_by\"]\n",
    "all_df = all_df.drop(unused_features, 1)\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing dates\n",
    "\n",
    "For now, we are going to use only year and month in which a pump has been built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_year(date):\n",
    "    if date != None:\n",
    "        return date[:4]\n",
    "    return 0\n",
    "\n",
    "def get_month(date):\n",
    "    if date != None:\n",
    "        return date[5:-3]\n",
    "    return 0\n",
    "\n",
    "all_df[\"year_recorded\"] = (all_df[\"date_recorded\"].apply(get_year)).astype('int')\n",
    "all_df[\"month_recorded\"] = all_df[\"date_recorded\"].apply(get_month).astype('int')\n",
    "\n",
    "#all_df = all_df.drop(\"date_recorded\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing string to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some float values are read as strings, so let's fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change from string to float\n",
    "all_df[\"amount_tsh\"] = pd.to_numeric(all_df.amount_tsh)\n",
    "\n",
    "# change from int to string\n",
    "# there's no visible pattern between years and defects, plus unkown construction year is saved as 0\n",
    "all_df[\"construction_year\"] = all_df[\"construction_year\"].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing unique categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of features have many unique values (e.g. there are many funders that only built 1 water pump). We are going to change all values with less than 10 occurrences into one group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/pandas/core/indexing.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = all_df.select_dtypes(include=['object'])\n",
    "\n",
    "for col in categorical_features:\n",
    "    val_counts = all_df[col].value_counts()\n",
    "    vals_to_remove = val_counts[val_counts <= 10].index.values\n",
    "    all_df[col].loc[all_df[col].isin(vals_to_remove)] = \"Many_Unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding (Option 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are changing categorical values to numerical ones. Maybe it's interesting to use dummy variables later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = all_df.select_dtypes(include=['object'])\n",
    "\n",
    "for col in all_df:\n",
    "    if col in categorical_features:\n",
    "        all_df[col] = pd.factorize(all_df[col])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dummy features (Option 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option generates more than 5000 columns, so we are going to skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(all_df.shape)\n",
    "#all_dummy_df = pd.get_dummies(all_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating train and test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 34), (14850, 34), (59400, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = all_df.loc[train.index]\n",
    "test_df = all_df.loc[test.index]\n",
    "\n",
    "train_df.shape, test_df.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some charts and see how interesting is the data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=train_df[\"year_recorded\"], hue=train_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=train_df[\"month_recorded\"], hue=train_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.countplot(x=train_df[\"extraction_type_class\"], hue=train_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.countplot(x=train_df[\"source_class\"], hue=train_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.countplot(x=train_df[\"waterpoint_type\"], hue=train_labels['status_group'])\n",
    "xt = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.countplot(x=train_df[\"payment\"], hue=train_labels['status_group'])\n",
    "xt = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.countplot(x=train_df[\"management_group\"], hue=train_labels['status_group'])\n",
    "xt = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.countplot(x=train_df[\"permit\"], hue=train_labels['status_group'])\n",
    "xt = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(train_df, train_labels[\"status_group\"], test_size=0.3)\n",
    "#train_df.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=100, n_jobs=3)\n",
    "alg.fit(train_df, train_labels[\"status_group\"])\n",
    "\n",
    "scores = cross_val_score(alg, train_df, train_labels[\"status_group\"], cv=3, )\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = GradientBoostingClassifier(random_state=1, n_estimators=100)\n",
    "alg.fit(train_df, train_labels[\"status_group\"])\n",
    "\n",
    "scores = cross_val_score(alg, train_df, train_labels[\"status_group\"], cv=3)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_df[\"extraction_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_df[\"extraction_type_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_df[\"extraction_type_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = []\n",
    "alg.append([RandomForestClassifier(random_state=1, n_estimators=10, n_jobs=3), train_df.columns])\n",
    "#alg.append([RandomForestClassifier(random_state=1, n_estimators=10, n_jobs=3), train_df.columns])\n",
    "alg.append([GradientBoostingClassifier(random_state=1, n_estimators=100), train_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'non functional')\n",
      "('non functional', 'non functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('non functional', 'non functional')\n",
      "('non functional', 'non functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('non functional', 'non functional')\n",
      "('non functional', 'non functional')\n",
      "('non functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('functional needs repair', 'functional')\n",
      "('non functional', 'non functional')\n",
      "('functional', 'functional')\n",
      "('non functional', 'functional')\n",
      "('non functional', 'non functional')\n",
      "('non functional', 'non functional')\n",
      "('functional', 'functional')\n",
      "('functional', 'functional')\n",
      "('non functional', 'non functional')\n",
      "('non functional', 'non functional')\n",
      "('functional needs repair', 'functional needs repair')\n",
      "('non functional', 'functional')\n"
     ]
    }
   ],
   "source": [
    "predictions = perform_ensemble(alg, train_df, train_labels[\"status_group\"], test_df)\n",
    "for i in range(30):\n",
    "    print(predictions[0][i], predictions[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_ensemble(algorithms, train_set, train_target, test_set):\n",
    "    total_predictions = []\n",
    "    for algorithm, predictor in algorithms:\n",
    "        algorithm.fit(train_set[predictor], train_target)\n",
    "        prediction = algorithm.predict(test_set[predictor])\n",
    "        \n",
    "        total_predictions.append(prediction)\n",
    "\n",
    "    # average scores \n",
    "    predictions = total_predictions#(total_predictions[0]*1  + total_predictions[1]*1)/ 2\n",
    "\n",
    "    #predictions[predictions <= .5] = 0\n",
    "    #predictions[predictions > .5] = 1\n",
    "    #predictions = predictions.astype(int)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
