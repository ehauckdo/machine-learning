{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump it Up: Data Mining the Water Table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition, we are trying to predict which water pumps are functional in some places in Tanzania. This competition is hosted by DrivenData[Add link] and the dataset is provided Taarifa[Add link] and the Tanzanian Ministry of Water[Add link]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"input/train.csv\",index_col=0)\n",
    "test = pd.read_csv(\"input/test.csv\",index_col=0)\n",
    "train_labels = pd.read_csv(\"input/train_labels.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train = pd.merge(train, train_labels, left_on=\"id\", right_on=\"id\")\n",
    "all_df = pd.concat((train, test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape, all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tNull checking, let's take care of these values\n",
    "#train.isnull().sum().sort_values(ascending=False).head(8)\n",
    "#test.isnull().sum().sort_values(ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df.replace(['Not Known'], ['unkown'], inplace=True)\n",
    "all_df.loc[all_df.scheme_name.isnull(), 'scheme_name'] = 'unknown'\n",
    "all_df.loc[all_df.scheme_management.isnull(), 'scheme_management'] = 'unknown'\n",
    "all_df.loc[all_df.funder.isnull(), 'funder'] = 'unknown'\n",
    "all_df.loc[all_df.installer.isnull(), 'installer'] = 'unknown'\n",
    "all_df.loc[all_df.subvillage.isnull(), 'subvillage'] = 'unknown'\n",
    "all_df.loc[all_df.public_meeting.isnull(), 'public_meeting'] = False\n",
    "all_df.loc[all_df.permit.isnull(), 'permit'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df.isnull().sum().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting unused features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are not going to use height, longitude and latitute. They demand more complex processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude_features = [\"gps_height\", \"longitude\", \"latitude\", \"recorded_by\"]\n",
    "all_df = all_df.drop(exclude_features, 1)\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing features\n",
    "\n",
    "### Processing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are going to use only year in which a pump has been built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_year(date):\n",
    "    if date != None:\n",
    "        return date[:4]\n",
    "    return 0\n",
    "\n",
    "all_df[\"date_recorded\"] = all_df[\"date_recorded\"].apply(get_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing string to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some float values are read as strings, so let's fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df[\"amount_tsh\"] = pd.to_numeric(all_df.amount_tsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing unique categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of features have many unique values (e.g. there are many funders that only built 1 water pump). We are going to change all values with less than 10 occurrences into one group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_features = all_df.select_dtypes(include=['object'])\n",
    "\n",
    "for col in categorical_features:\n",
    "    val_counts = all_df[col].value_counts()\n",
    "    vals_to_remove = val_counts[val_counts <= 10].index.values\n",
    "    all_df[col].loc[all_df[col].isin(vals_to_remove)] = \"Many_Unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding (Option 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are changing categorical values to numerical ones. Maybe it's interesting to use dummy variables later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = all_df.select_dtypes(include=['object'])\n",
    "\n",
    "for col in all_df:\n",
    "    if col in categorical_features:\n",
    "        all_df[col] = pd.factorize(all_df[col])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dummy features (Option 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option generates more than 5000 columns, so we are going to skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(all_df.shape)\n",
    "#all_dummy_df = pd.get_dummies(all_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating train and test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = all_df.loc[train.index]\n",
    "test_df = all_df.loc[test.index]\n",
    "\n",
    "train_df.shape, test_df.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(train_df, train_labels[\"status_group\"], test_size=0.3)\n",
    "#train_df.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, n_jobs=3)\n",
    "alg.fit(train_df, train_labels[\"status_group\"])\n",
    "\n",
    "scores = cross_val_score(alg, train_df, train_labels[\"status_group\"], cv=3, )\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = GradientBoostingClassifier(random_state=1)\n",
    "alg.fit(train_df, train_labels[\"status_group\"])\n",
    "\n",
    "scores = cross_val_score(alg, train_df, train_labels[\"status_group\"], cv=3)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
